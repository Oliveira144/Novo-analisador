import streamlit as st
import numpy as np
import pandas as pd
from collections import deque, Counter
import math
from datetime import datetime

# =====================================
# CONFIGURA√á√ïES PROFISSIONAIS
# =====================================

st.set_page_config(
    page_title="Football Studio Pro Analytics",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Profissional
st.markdown("""
<style>
    .main-container {
        padding: 0;
    }
    .header-section {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 0 0 20px 20px;
        color: white;
        margin-bottom: 2rem;
        text-align: center;
    }
    .metric-professional {
        background: white;
        border: 1px solid #e1e5e9;
        border-radius: 8px;
        padding: 1.5rem;
        margin: 0.5rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .statistical-section {
        background: #f8f9fa;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        border-left: 4px solid #007bff;
    }
    .alert-professional {
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        font-weight: 500;
    }
    .alert-high { background: #d1ecf1; border-left: 4px solid #0c5460; }
    .alert-medium { background: #fff3cd; border-left: 4px solid #856404; }
    .alert-low { background: #f8d7da; border-left: 4px solid #721c24; }
    .data-table {
        font-family: 'Courier New', monospace;
        font-size: 0.9rem;
    }
    .confidence-bar {
        background: #e9ecef;
        border-radius: 10px;
        height: 8px;
        overflow: hidden;
    }
    .confidence-fill {
        height: 100%;
        border-radius: 10px;
        transition: width 0.3s ease;
    }
</style>
""", unsafe_allow_html=True)

# =====================================
# CLASSE PRINCIPAL DE AN√ÅLISE
# =====================================

class FootballStudioAnalyzer:
    def __init__(self):
        self.outcomes = {'C': 0, 'V': 1, 'E': 2}  # Casa, Visitante, Empate
        self.outcome_names = {0: 'Casa', 1: 'Visitante', 2: 'Empate'}
        self.min_sample_size = 30  # M√≠nimo para an√°lises estat√≠sticas confi√°veis
        
    def encode_sequence(self, sequence):
        """Converte sequ√™ncia de strings para n√∫meros"""
        return [self.outcomes[x] for x in sequence if x in self.outcomes]
    
    def calculate_transition_matrix(self, sequence):
        """Calcula matriz de transi√ß√£o de estados"""
        if len(sequence) < 10:
            return None, 0
            
        encoded = self.encode_sequence(sequence)
        if len(encoded) < 10:
            return None, 0
            
        # Matriz 3x3 para as transi√ß√µes
        matrix = np.zeros((3, 3))
        
        for i in range(len(encoded) - 1):
            current_state = encoded[i]
            next_state = encoded[i + 1]
            matrix[current_state][next_state] += 1
        
        # Normaliza para probabilidades
        row_sums = matrix.sum(axis=1)
        transition_matrix = np.divide(matrix, row_sums[:, np.newaxis], 
                                    out=np.zeros_like(matrix), where=row_sums[:, np.newaxis]!=0)
        
        # Calcula confiabilidade baseada no tamanho da amostra
        reliability = min(1.0, len(encoded) / 100)  # 100+ observa√ß√µes = confiabilidade m√°xima
        
        return transition_matrix, reliability
    
    def chi_square_independence_test(self, sequence):
        """Teste Chi-quadrado para independ√™ncia (implementa√ß√£o pr√≥pria)"""
        if len(sequence) < 20:
            return None, None, 0
            
        encoded = self.encode_sequence(sequence)
        if len(encoded) < 20:
            return None, None, 0
            
        # Cria tabela de conting√™ncia para pares consecutivos
        contingency = np.zeros((3, 3))
        for i in range(len(encoded) - 1):
            contingency[encoded[i]][encoded[i + 1]] += 1
        
        if contingency.sum() == 0:
            return None, None, 0
            
        try:
            # Calcula valores esperados
            row_totals = contingency.sum(axis=1)
            col_totals = contingency.sum(axis=0)
            total = contingency.sum()
            
            expected = np.outer(row_totals, col_totals) / total
            
            # Calcula chi-quadrado
            chi2 = np.sum((contingency - expected)**2 / (expected + 1e-10))
            
            # Graus de liberdade
            dof = (contingency.shape[0] - 1) * (contingency.shape[1] - 1)
            
            # Aproxima√ß√£o do p-valor usando distribui√ß√£o normal
            # Para grandes amostras, chi2 aproxima normal
            if dof > 0:
                p_value = 1 - self._normal_cdf((chi2 - dof) / math.sqrt(2 * dof))
            else:
                p_value = 0.5
                
            return chi2, max(0, min(1, p_value)), min(1.0, len(encoded) / 50)
        except:
            return None, None, 0
    
    def _normal_cdf(self, x):
        """Fun√ß√£o de distribui√ß√£o cumulativa normal padr√£o (aproxima√ß√£o)"""
        return 0.5 * (1 + math.erf(x / math.sqrt(2)))
    
    def runs_test(self, sequence):
        """Teste de corridas para aleatoriedade (implementa√ß√£o pr√≥pria)"""
        if len(sequence) < 15:
            return None, None, 0
            
        encoded = self.encode_sequence(sequence)
        if len(encoded) < 15:
            return None, None, 0
            
        # Converte para bin√°rio (Casa vs N√£o-Casa)
        binary = [1 if x == 0 else 0 for x in encoded]
        
        n1 = sum(binary)  # N√∫mero de Casas
        n2 = len(binary) - n1  # N√∫mero de N√£o-Casas
        
        if n1 == 0 or n2 == 0:
            return None, None, 0
            
        # Conta o n√∫mero de corridas
        runs = 1
        for i in range(1, len(binary)):
            if binary[i] != binary[i-1]:
                runs += 1
        
        # Estat√≠stica do teste
        expected_runs = ((2 * n1 * n2) / (n1 + n2)) + 1
        variance = (2 * n1 * n2 * (2 * n1 * n2 - n1 - n2)) / ((n1 + n2) ** 2 * (n1 + n2 - 1))
        
        if variance <= 0:
            return None, None, 0
            
        z_score = (runs - expected_runs) / math.sqrt(variance)
        p_value = 2 * (1 - self._normal_cdf(abs(z_score)))
        
        return z_score, max(0, min(1, p_value)), min(1.0, len(encoded) / 40)
    
    def autocorrelation_analysis(self, sequence, max_lag=10):
        """An√°lise de autocorrela√ß√£o para detectar padr√µes temporais"""
        if len(sequence) < 25:
            return None, 0
            
        encoded = self.encode_sequence(sequence)
        if len(encoded) < 25:
            return None, 0
            
        autocorrs = []
        for lag in range(1, min(max_lag + 1, len(encoded) // 3)):
            if len(encoded) - lag < 5:
                break
                
            x1 = np.array(encoded[:-lag])
            x2 = np.array(encoded[lag:])
            
            if len(x1) == 0 or len(x2) == 0:
                continue
                
            # Calcula correla√ß√£o de Pearson manualmente
            try:
                mean_x1 = np.mean(x1)
                mean_x2 = np.mean(x2)
                
                numerator = np.sum((x1 - mean_x1) * (x2 - mean_x2))
                denominator = math.sqrt(np.sum((x1 - mean_x1)**2) * np.sum((x2 - mean_x2)**2))
                
                if denominator > 0:
                    corr = numerator / denominator
                    if not math.isnan(corr):
                        autocorrs.append((lag, corr))
            except:
                continue
        
        reliability = min(1.0, len(encoded) / 60)
        return autocorrs, reliability
    
    def frequency_domain_analysis(self, sequence):
        """An√°lise no dom√≠nio da frequ√™ncia usando FFT"""
        if len(sequence) < 32:
            return None, 0
            
        encoded = self.encode_sequence(sequence)
        if len(encoded) < 32:
            return None, 0
            
        # Remove a tend√™ncia (detrend)
        detrended = np.array(encoded) - np.mean(encoded)
        
        # FFT
        fft_result = np.fft.fft(detrended)
        freqs = np.fft.fftfreq(len(detrended))
        
        # Pega apenas frequ√™ncias positivas
        positive_freqs = freqs[:len(freqs)//2]
        magnitude = np.abs(fft_result[:len(fft_result)//2])
        
        # Encontra picos significativos
        if len(magnitude) > 3:
            threshold = np.mean(magnitude) + 2 * np.std(magnitude)
            peaks = [(positive_freqs[i], magnitude[i]) for i in range(1, len(magnitude)) 
                    if magnitude[i] > threshold]
            
            # Converte frequ√™ncia para per√≠odo
            periods = [(1/freq if freq > 0 else 0, mag) for freq, mag in peaks]
            periods = [(p, m) for p, m in periods if 2 <= p <= len(encoded)//3]
            
            reliability = min(1.0, len(encoded) / 80)
            return sorted(periods, key=lambda x: x[1], reverse=True)[:5], reliability
        
        return [], 0
    
    def entropy_analysis(self, sequence):
        """An√°lise de entropia de Shannon"""
        if len(sequence) < 10:
            return 0, 0
            
        encoded = self.encode_sequence(sequence)
        if len(encoded) < 10:
            return 0, 0
            
        # Entropia de Shannon
        counter = Counter(encoded)
        total = len(encoded)
        
        entropy = 0
        for count in counter.values():
            if count > 0:
                p = count / total
                entropy -= p * math.log2(p)
        
        # Normaliza (m√°ximo para 3 estados √© log2(3))
        max_entropy = math.log2(3)
        normalized_entropy = entropy / max_entropy
        
        reliability = min(1.0, len(encoded) / 30)
        return normalized_entropy, reliability
    
    def markov_chain_prediction(self, sequence):
        """Predi√ß√£o baseada em cadeia de Markov"""
        if len(sequence) < 20:
            return None, 0
            
        transition_matrix, reliability = self.calculate_transition_matrix(sequence)
        if transition_matrix is None:
            return None, 0
            
        # Estado atual
        current_state = self.outcomes.get(sequence[-1])
        if current_state is None:
            return None, 0
            
        # Probabilidades do pr√≥ximo estado
        next_probs = transition_matrix[current_state]
        
        # Verifica se h√° diferen√ßa significativa
        if np.max(next_probs) - np.min(next_probs) < 0.1:  # Diferen√ßa < 10%
            return None, reliability * 0.5
            
        predicted_state = np.argmax(next_probs)
        confidence = next_probs[predicted_state]
        
        # Converte de volta para string
        prediction = [k for k, v in self.outcomes.items() if v == predicted_state][0]
        
        return {
            'prediction': prediction,
            'confidence': confidence * 100,
            'probabilities': {
                'C': next_probs[0] * 100,
                'V': next_probs[1] * 100,
                'E': next_probs[2] * 100
            }
        }, reliability

    def pattern_detection(self, sequence):
        """Detecta padr√µes repetitivos na sequ√™ncia"""
        if len(sequence) < 6:
            return []
            
        patterns = []
        
        # Procura por padr√µes de tamanho 2 a 6
        for pattern_length in range(2, min(7, len(sequence) // 3)):
            pattern_counts = Counter()
            
            for i in range(len(sequence) - pattern_length + 1):
                pattern = tuple(sequence[i:i + pattern_length])
                pattern_counts[pattern] += 1
            
            # Considera apenas padr√µes que aparecem mais de 1 vez
            for pattern, count in pattern_counts.items():
                if count > 1:
                    significance = count / (len(sequence) - pattern_length + 1)
                    if significance > 0.1:  # Pelo menos 10% de ocorr√™ncia
                        patterns.append({
                            'pattern': list(pattern),
                            'count': count,
                            'length': pattern_length,
                            'significance': significance
                        })
        
        return sorted(patterns, key=lambda x: x['significance'], reverse=True)[:5]

# =====================================
# INICIALIZA√á√ÉO
# =====================================

if "history" not in st.session_state:
    st.session_state.history = deque(maxlen=1000)
if "timestamps" not in st.session_state:
    st.session_state.timestamps = deque(maxlen=1000)

analyzer = FootballStudioAnalyzer()

# =====================================
# INTERFACE PRINCIPAL
# =====================================

# Header
st.markdown("""
<div class="header-section">
    <h1>üèà Football Studio Pro Analytics</h1>
    <p>An√°lise estat√≠stica profissional baseada em m√©todos matem√°ticos rigorosos</p>
</div>
""", unsafe_allow_html=True)

# Sidebar de configura√ß√µes
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    confidence_threshold = st.slider("Limiar de confian√ßa (%)", 50, 95, 70)
    show_statistical_tests = st.checkbox("Mostrar testes estat√≠sticos", True)
    show_advanced_metrics = st.checkbox("M√©tricas avan√ßadas", True)
    min_predictions = st.number_input("M√≠n. jogos para predi√ß√£o", 10, 100, 20)
    
    st.header("üìä Resumo da Sess√£o")
    if st.session_state.history:
        total = len([x for x in st.session_state.history if x in ['C','V','E']])
        if total > 0:
            counter = Counter([x for x in st.session_state.history if x in ['C','V','E']])
            st.metric("Total de jogos", total)
            for outcome, name in [('C', 'Casa'), ('V', 'Visitante'), ('E', 'Empate')]:
                count = counter.get(outcome, 0)
                pct = (count / total) * 100
                st.write(f"{name}: {count} ({pct:.1f}%)")

# Controles de entrada
st.subheader("üì• Registro de Resultados")
col1, col2, col3, col4, col5 = st.columns([2, 2, 2, 1, 1])

with col1:
    if st.button("üè† CASA", use_container_width=True, type="primary"):
        st.session_state.history.append('C')
        st.session_state.timestamps.append(datetime.now())
        st.rerun()

with col2:
    if st.button("‚úàÔ∏è VISITANTE", use_container_width=True, type="primary"):
        st.session_state.history.append('V')
        st.session_state.timestamps.append(datetime.now())
        st.rerun()

with col3:
    if st.button("‚öñÔ∏è EMPATE", use_container_width=True, type="primary"):
        st.session_state.history.append('E')
        st.session_state.timestamps.append(datetime.now())
        st.rerun()

with col4:
    if st.button("‚Ü∂", help="Desfazer"):
        if st.session_state.history:
            st.session_state.history.pop()
            if st.session_state.timestamps:
                st.session_state.timestamps.pop()
            st.rerun()

with col5:
    if st.button("üóëÔ∏è", help="Limpar"):
        st.session_state.history.clear()
        st.session_state.timestamps.clear()
        st.rerun()

# =====================================
# AN√ÅLISES ESTAT√çSTICAS PRINCIPAIS
# =====================================

sequence = [x for x in st.session_state.history if x in ['C','V','E']]

if len(sequence) >= 10:
    
    # Predi√ß√£o Markoviana
    st.subheader("üéØ Predi√ß√£o Estat√≠stica (Cadeia de Markov)")
    
    if len(sequence) >= min_predictions:
        prediction_result, reliability = analyzer.markov_chain_prediction(sequence)
        
        if prediction_result and reliability > 0.3:
            pred = prediction_result['prediction']
            conf = prediction_result['confidence']
            probs = prediction_result['probabilities']
            
            # Determina o n√≠vel de confian√ßa
            if conf >= confidence_threshold:
                alert_class = "alert-high"
                icon = "üü¢"
                status = "ALTA CONFIAN√áA"
            elif conf >= confidence_threshold * 0.7:
                alert_class = "alert-medium"
                icon = "üü°"
                status = "CONFIAN√áA MODERADA"
            else:
                alert_class = "alert-low"
                icon = "üî¥"
                status = "BAIXA CONFIAN√áA"
            
            outcome_names = {'C': 'CASA üè†', 'V': 'VISITANTE ‚úàÔ∏è', 'E': 'EMPATE ‚öñÔ∏è'}
            
            st.markdown(f"""
            <div class="alert-professional {alert_class}">
                <h3>{icon} PREDI√á√ÉO: {outcome_names[pred]}</h3>
                <p><strong>Confian√ßa:</strong> {conf:.1f}% | <strong>Status:</strong> {status}</p>
                <p><strong>Confiabilidade do modelo:</strong> {reliability*100:.1f}%</p>
                <p><strong>Base estat√≠stica:</strong> {len(sequence)} observa√ß√µes</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Mostra todas as probabilidades
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üè† Casa", f"{probs['C']:.1f}%")
            with col2:
                st.metric("‚úàÔ∏è Visitante", f"{probs['V']:.1f}%")
            with col3:
                st.metric("‚öñÔ∏è Empate", f"{probs['E']:.1f}%")
        else:
            st.info("üìä Dados insuficientes ou padr√£o n√£o detectado para predi√ß√£o confi√°vel")
    else:
        st.info(f"üìä Aguardando mais dados... ({len(sequence)}/{min_predictions} jogos m√≠nimos)")

    # Matriz de Transi√ß√£o
    if show_advanced_metrics and len(sequence) >= 15:
        st.subheader("üìä Matriz de Transi√ß√£o de Estados")
        
        transition_matrix, reliability = analyzer.calculate_transition_matrix(sequence)
        if transition_matrix is not None:
            
            # Cria DataFrame para exibi√ß√£o
            df_matrix = pd.DataFrame(
                transition_matrix * 100,  # Converte para percentual
                columns=['Casa', 'Visitante', 'Empate'],
                index=['Casa ‚Üí', 'Visitante ‚Üí', 'Empate ‚Üí']
            )
            
            st.write("**Probabilidades de transi√ß√£o (%):**")
            st.dataframe(df_matrix.round(1), use_container_width=True)
            
            st.write(f"**Confiabilidade:** {reliability*100:.1f}% (baseada em {len(sequence)} observa√ß√µes)")
            
            # Interpreta√ß√£o
            max_prob = np.max(transition_matrix)
            if max_prob > 0.6:
                st.warning("‚ö†Ô∏è Padr√£o determin√≠stico detectado - sequ√™ncia pode n√£o ser aleat√≥ria")
            elif max_prob < 0.4:
                st.success("‚úÖ Distribui√ß√£o equilibrada - comportamento pr√≥ximo ao aleat√≥rio")

    # Testes Estat√≠sticos
    if show_statistical_tests and len(sequence) >= 20:
        st.subheader("üî¨ Testes de Hip√≥tese Estat√≠stica")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="statistical-section">
                <h4>Teste Chi-quadrado (Independ√™ncia)</h4>
            """, unsafe_allow_html=True)
            
            chi2, p_value, reliability = analyzer.chi_square_independence_test(sequence)
            if chi2 is not None:
                alpha = 0.05
                is_independent = p_value > alpha
                
                st.write(f"**Chi¬≤ = {chi2:.3f}**")
                st.write(f"**p-valor = {p_value:.4f}**")
                st.write(f"**Confiabilidade: {reliability*100:.1f}%**")
                
                if is_independent:
                    st.success("‚úÖ N√£o h√° evid√™ncia de depend√™ncia (sequ√™ncia aleat√≥ria)")
                else:
                    st.error("‚ùå Evid√™ncia de depend√™ncia detectada (padr√£o presente)")
            
            st.markdown("</div>", unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="statistical-section">
                <h4>Teste de Corridas (Aleatoriedade)</h4>
            """, unsafe_allow_html=True)
            
            z_score, p_value, reliability = analyzer.runs_test(sequence)
            if z_score is not None:
                alpha = 0.05
                is_random = p_value > alpha
                
                st.write(f"**Z-score = {z_score:.3f}**")
                st.write(f"**p-valor = {p_value:.4f}**")
                st.write(f"**Confiabilidade: {reliability*100:.1f}%**")
                
                if is_random:
                    st.success("‚úÖ Sequ√™ncia compat√≠vel com aleatoriedade")
                else:
                    st.error("‚ùå Sequ√™ncia n√£o-aleat√≥ria detectada")
            
            st.markdown("</div>", unsafe_allow_html=True)

    # An√°lise de Autocorrela√ß√£o
    if show_advanced_metrics and len(sequence) >= 25:
        st.subheader("üìà An√°lise de Autocorrela√ß√£o Temporal")
        
        autocorrs, reliability = analyzer.autocorrelation_analysis(sequence)
        if autocorrs and reliability > 0.2:
            
            # Cria DataFrame para visualiza√ß√£o
            df_autocorr = pd.DataFrame(autocorrs, columns=['Lag', 'Correla√ß√£o'])
            df_autocorr['Correla√ß√£o_Abs'] = df_autocorr['Correla√ß√£o'].abs()
            df_autocorr = df_autocorr.sort_values('Correla√ß√£o_Abs', ascending=False)
            
            st.write(f"**Correla√ß√µes mais significativas (confiabilidade: {reliability*100:.1f}%):**")
            
            for _, row in df_autocorr.head(5).iterrows():
                lag = int(row['Lag'])
                corr = row['Correla√ß√£o']
                
                if abs(corr) > 0.3:
                    significance = "üî¥ FORTE"
                elif abs(corr) > 0.15:
                    significance = "üü° MODERADA"
                else:
                    significance = "üü¢ FRACA"
                    
                st.write(f"‚Ä¢ **Lag {lag}:** {corr:.3f} ({significance})")
                
                if abs(corr) > 0.25:
                    st.write(f"  ‚Ü≥ Padr√£o c√≠clico de per√≠odo {lag} detectado")

    # An√°lise de Entropia
    if show_advanced_metrics and len(sequence) >= 15:
        st.subheader("üßÆ An√°lise de Entropia Informacional")
        
        entropy, reliability = analyzer.entropy_analysis(sequence)
        if reliability > 0.3:
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Entropia Normalizada", f"{entropy:.3f}")
            
            with col2:
                predictability = (1 - entropy) * 100
                st.metric("Predictibilidade", f"{predictability:.1f}%")
            
            with col3:
                st.metric("Confiabilidade", f"{reliability*100:.1f}%")
            
            # Interpreta√ß√£o
            if entropy > 0.95:
                st.success("‚úÖ Alta aleatoriedade - distribui√ß√£o muito equilibrada")
            elif entropy > 0.85:
                st.info("‚ÑπÔ∏è Aleatoriedade moderada - leve desvio da uniformidade")
            elif entropy > 0.70:
                st.warning("‚ö†Ô∏è Baixa aleatoriedade - padr√µes evidentes")
            else:
                st.error("‚ùå Muito baixa aleatoriedade - forte presen√ßa de padr√µes")

    # Detec√ß√£o de Padr√µes
    if show_advanced_metrics and len(sequence) >= 12:
        st.subheader("üîç Detec√ß√£o de Padr√µes Repetitivos")
        
        patterns = analyzer.pattern_detection(sequence)
        if patterns:
            st.write("**Padr√µes significativos detectados:**")
            
            for i, pattern in enumerate(patterns[:5], 1):
                pattern_str = " ‚Üí ".join(pattern['pattern'])
                significance_pct = pattern['significance'] * 100
                
                if pattern['significance'] > 0.3:
                    strength = "üî¥ MUITO FORTE"
                elif pattern['significance'] > 0.2:
                    strength = "üü° FORTE"
                else:
                    strength = "üü¢ MODERADO"
                
                st.write(f"**{i}. {pattern_str}**")
                st.write(f"   ‚Ü≥ Ocorr√™ncias: {pattern['count']} | Signific√¢ncia: {significance_pct:.1f}% ({strength})")

# =====================================
# HIST√ìRICO E M√âTRICAS B√ÅSICAS
# =====================================

if sequence:
    st.subheader("üìã Dados Hist√≥ricos")
    
    # √öltimas 30 jogadas
    recent = sequence[-30:] if len(sequence) > 30 else sequence
    
    # Organiza em tabela
    rows = []
    for i in range(0, len(recent), 10):
        row = recent[i:i+10]
        # Preenche com espa√ßos se necess√°rio
        while len(row) < 10:
            row.append("")
        rows.append(row)
    
    if rows:
        df_history = pd.DataFrame(rows, columns=[f"Pos {i+1}" for i in range(10)])
        
        # Substitui s√≠mbolos para melhor visualiza√ß√£o
        df_display = df_history.replace({'C': 'üè†', 'V': '‚úàÔ∏è', 'E': '‚öñÔ∏è', '': ''})
        
        st.write("**√öltimas 30 jogadas (mais recentes √† direita):**")
        st.dataframe(df_display, use_container_width=True, hide_index=True)

    # Estat√≠sticas descritivas
    st.subheader("üìà Estat√≠sticas Descritivas")
    
    col1, col2, col3, col4 = st.columns(4)
    
    counter = Counter(sequence)
    total = len(sequence)
    
    with col1:
        casa_pct = (counter.get('C', 0) / total) * 100
        st.metric("üè† Casa", f"{counter.get('C', 0)} ({casa_pct:.1f}%)")
    
    with col2:
        visit_pct = (counter.get('V', 0) / total) * 100
        st.metric("‚úàÔ∏è Visitante", f"{counter.get('V', 0)} ({visit_pct:.1f}%)")
    
    with col3:
        empate_pct = (counter.get('E', 0) / total) * 100
        st.metric("‚öñÔ∏è Empate", f"{counter.get('E', 0)} ({empate_pct:.1f}%)")
    
    with col4:
        st.metric("üìä Total", f"{total} jogos")

else:
    st.info("üëÜ Comece registrando alguns resultados para ver as an√°lises estat√≠sticas")

# =====================================
# RODAP√â INFORMATIVO
# =====================================

st.markdown("---")
